import time
import threading
import random
from src.utils.url_builder import build_nitter_url
from src.store_tweets import fetch_and_store_tweets
from src.config import NITTER_SERVERS, SEARCH_QUERIES, FETCH_INTERVAL, MAX_RETRIES, RETRY_INTERVAL

def get_nitter_server():
    """Ø§Ù†ØªØ®Ø§Ø¨ ØªØµØ§Ø¯ÙÛŒ ÛŒÚ© Ø³Ø±ÙˆØ± Nitter Ø¨Ø±Ø§ÛŒ ØªÙˆØ²ÛŒØ¹ Ø¨Ø§Ø± Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Failover"""
    return random.choice(NITTER_SERVERS)

def scheduled_task():
    """Ø§Ø¬Ø±Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø³ØªÙ…Ø±"""
    while True:
        print("â³ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
        for query in SEARCH_QUERIES:
            success = False
            for attempt in range(MAX_RETRIES):
                server = get_nitter_server()
                rss_url = build_nitter_url(server, query)  # âœ… Ø­Ø§Ù„Ø§ Ú©ÙˆØ¦Ø±ÛŒ Ø¯Ø±Ø³Øª Ø³Ø§Ø®ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.

                try:
                    print(f"ğŸ“¡ Ø¯Ø±ÛŒØ§ÙØª ØªÙˆÛŒÛŒØªâ€ŒÙ‡Ø§ Ø§Ø²: {rss_url}")
                    fetch_and_store_tweets(rss_url, query)  # âœ… Ø§Ø±Ø³Ø§Ù„ `search_query`
                    success = True
                    break
                except Exception as e:
                    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ '{query}' Ø§Ø² {server}: {e}")
                    time.sleep(RETRY_INTERVAL)

            if not success:
                print(f"âš ï¸ Ø¹Ø¯Ù… Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ '{query}' Ù¾Ø³ Ø§Ø² {MAX_RETRIES} ØªÙ„Ø§Ø´!")

        print(f"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯. Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø¯Ø± {FETCH_INTERVAL} Ø«Ø§Ù†ÛŒÙ‡...")
        time.sleep(FETCH_INTERVAL)

def start_scheduler():
    """Ø§Ø¬Ø±Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø± ÛŒÚ© ØªØ±Ø¯ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ù„Ø§Ú© Ø´Ø¯Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡"""
    scheduler_thread = threading.Thread(target=scheduled_task, daemon=True)
    scheduler_thread.start()
